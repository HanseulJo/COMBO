# COMBO + NK model
- Combinatorial Bayesian Optimizationusing the Graph Cartesian Product, Advances in neural information processing systems(NeurIPS), 2019
- (HanseulJo) Application of COMBO on NK model. ( https://en.wikipedia.org/wiki/NK_model )

## 1. Set up
####1. Set a conda virtual environment
```bash
conda create -n COMBO python=3.7 anaconda --yes
```

####2. Clone the repository
```bash
git clone https://github.com/QUVA-Lab/COMBO.git
git clone https://github.com/HanseulJo/COMBO.git
```

####3. Install required packages
```bash
conda activate COMBO
conda install --file requirements.txt
```
If the second line above does not work, then run:  (installing pytorch: refer to https://pytorch.org/get-started/previous-versions/#v160 )
```bash
conda install -c conda-forge gputil
conda install -c conda-forge psutil
conda install -c conda-forge simanneal==0.4.2
conda install -c conda-forge toposort
conda install pytorch==1.6.0 torchvision==0.7.0 -c pytorch 
```
Note (HanseulJo): Please install matplotlib and tensorboard manually.
```bash
conda install matplotlib
conda install -c conda-forge tensorboard 
```


## 2. Run (Original version, not HanseulJo's.)
####1. Consigure directories
All necessary directories can be configured in the file **COMBO/config.py**

####2. Arguments
* --n_eval : The number of evaluations
* --objective : For reproducing, you can chooose one of ['branin', 'ising', 'contamination', 'pestcontrol', 'maxsat28', 'maxsat43', 'maxsat60', 'nasbinary']. For your own defined objectives, your objective function name should be given.
* --random_seed_config : Some objectives are generated by some random processes. In order to control it random seeds are given to determine random processes and initial input points for evaluations with which COMBO begin.
* --parallel : The acquisition function optimization in COMBO uses multiple initial points. This multiple optimization can be done in parallel using multiprocesses with this option.
* --device : Only valid for ['nasbinary'] which uses GPU for its evalutions.
* --lamda : The regularization coefficient only valid for ['ising', 'contamination']
* --path : A path to the directory of the experiment to be continued.(Only need when you want to resume an experiment)

####3. Examples
```bash
python COMBO/main.py --objective ising --n_eval 150 --random_seed_config 7 --lamda 0.01
```
To optimize 'ising' with 0.01 for the regularization coefficient with 150 evaluations

```bash
python COMBO/main.py --objective pestcontrol --n_eval 300 --random_seed_config 3
```
To optimize 'pestcontrol' with 300 evaluations

## 3. Modification log (By HanseulJo)

### main_NKmodel.py
* Run this file for an experiment solving NK model optimization with COMBO.
* Class "NKmodel" constructs an NKmodel. It initially generates a random (or you can fix an) interdependence matrix (--> self.interdependence) and a random  (or you can fix an) contribution map (--> self.contributions). You can calculate fitness value for each status (tuple of length N), whole landscape, global optimum, etc. with class methods.
* Example run1: Random initial points.
```bash
python ./main_NKmodel.py --N 6 --K 1 --A 2 --n_eval 20 --interdependency_seed 0 --payoff_seed 0
```
* Example run2: Start from the states with minimum fitness values.
```bash
python ./main_NKmodel.py --N 6 --K 1 --A 2 --n_eval 18 --interdependency_seed 10 --payoff_seed 15 --start_from_bottom
```
* Example run3: Every acquisition optimization step do a flip of a locus from the previous state. (in COMBO, and Random Walk)
```bash
python ./main_NKmodel.py --N 6 --K 1 --A 2 --n_eval 18 --interdependency_seed 70 --payoff_seed 68 --local_search
```

* Additional arguments:
* - "--N": The number of loci
* - "--K": The number of the other loci which have effects on each locus.
* - "--A": The number of states that each locus can have.
* - "--model_info_path": Path to save interdependence matrix("knowledge.txt") and a table of fitness landscape with contributions("landscape.txt"). If it is None (not given), then the interdependence matrix and landscape will be printed through stdout after the BO runs.
* - "--interdependency_seed": Random seed to fix an interdependency matrix. If not specified, it will be chosen randomly between 0 ~ 99.
* - "--payoff_seed": Random seed to fix payoff structure (contribution map), given '--interdependency_seed'. If not specified, it will be chosen randomly between 0 ~ 99.
* - "--init_point_seed": Random seed to fix initial points (usually, 2 points), given '--interdependency_seed'. If not specified, it will be chosen randomly between 0 ~ 99.
* - "--start_from_bottom": If you use this option, then the initial points will be changed into (usually, two of) states with the first several minimum fitness values.
* - "--local_search": If you use this option, then every searching step (more exactly, acquisition optimizattion) will do a flip on single locus of previous state. (Since we choose 2 initial points, the first locus-flip is done for an initial point with less fitness value (closer-to-optimum).)

* Removed arguments:
* - "--lamda", "--random_seed_config"

### main.py:
* Note: "COMBO/main.py" file has been moved outside of the folder "COMBO/". This prevents error relevant to modules.
* Some lines are modified from the original version.

### run_multiple_times.py

### average_graphs.py
